Developed at ISRO (U.R. Rao Satellite Centre, Bangalore)

This project enables fine-tuning of Llama-3.2-3B-Instruct on multiple PDF documents. It extracts text using OCR (Tesseract) when necessary and allows users to train a model based on PDF content for question-answering and summarization.

ğŸ“Œ Features
âœ… Fine-tunes Llama-3.2-3B-Instruct on multiple PDFs
âœ… Uses OCR (Tesseract) to extract text from scanned PDFs
âœ… Allows users to ask multiple questions post-training
âœ… Customizable training parameters (learning rate, max steps, etc.)
âœ… Streamlit UI for easy interaction
âœ… Runs entirely offline after setup

ğŸ›  Setup Instructions (Linux)
1ï¸âƒ£ Clone the Repository
git clone https://github.com/rohanmalik102003/-Multi-PDF-Model-Fine-Tuning-and-Inference.git
cd multi-pdf-finetuning

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Download the Model (Llama-3.2-3B-Instruct)
git clone https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-bnb-4bit models/Llama-3.2-3B-Instruct-bnb-4bit
ğŸ“Œ Ensure the model is inside models/ before running the application.

ğŸš€ Usage
Start the Streamlit Application
streamlit run PDF.py

ğŸ”¹ Open the browser at http://localhost:8501
ğŸ”¹ Upload multiple PDF files for training
ğŸ”¹ Fine-tune the model using the UI
ğŸ”¹ Ask multiple questions based on the trained model
